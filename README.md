# ğŸ§  Mosaic Agent - Interface Codage IA

Une interface web locale qui centralise et intÃ¨gre les meilleurs outils d'IA open source pour crÃ©er une IA personnelle Ã©volutive. SpÃ©cialement optimisÃ© pour **MacBook Pro 2015 (macOS 12.7.6, 8GB RAM, CPU Intel)**.

## ğŸ¯ Objectif

CrÃ©er une **application unique** qui rassemble tous les outils d'IA sophistiquÃ©s dans une interface de contrÃ´le centralisÃ©e, permettant d'expÃ©rimenter, configurer et connecter ces modules entre eux facilement.

## âœ¨ FonctionnalitÃ©s

- ğŸ›ï¸ **Tableau de bord unifiÃ©** pour tous vos outils IA
- ğŸ”§ **Gestion des services** (dÃ©marrage/arrÃªt en un clic)
- ğŸ“Š **Monitoring systÃ¨me** en temps rÃ©el (RAM, CPU, services actifs)
- âš™ï¸ **Configuration optimisÃ©e** pour MacBook Pro 2015
- ğŸ“š **Documentation intÃ©grÃ©e** et guides d'installation
- ğŸ”— **IntÃ©gration API** pour tous les services
- ğŸ“± **Interface responsive** moderne avec Tailwind CSS

## ğŸ› ï¸ Outils IA IntÃ©grÃ©s

| Outil | Statut | Description | CompatibilitÃ© Mac 2015 |
|-------|--------|-------------|-------------------------|
| **Ollama** | âœ… | Serveur LLM local (LLaMA, Mistral, CodeLlama) | Excellent avec modÃ¨les quantifiÃ©s |
| **Whisper.cpp** | âœ… | Transcription audio locale ultra-rapide | Optimal sur CPU Intel |
| **ChromaDB** | âœ… | Base de donnÃ©es vectorielle pour embeddings | Compatible, mÃ©moire optimisÃ©e |
| **LangChain** | âœ… | Framework pour agents IA et chaÃ®nes de prompts | Parfait pour expÃ©rimentation |
| **JupyterLab** | âœ… | IDE interactif pour dÃ©veloppement IA | IdÃ©al pour prototypage |
| **LM Studio** | âš ï¸ | Interface GUI pour LLM (limitÃ© sans GPU) | Utilisable mais Ollama recommandÃ© |
| **Stable Diffusion** | âŒ | GÃ©nÃ©ration d'images (trop lent sur CPU) | Cloud recommandÃ© |
| **Docker** | âœ… | Conteneurisation pour isolation des services | Essentiel pour gestion propre |

## ğŸš€ Installation Rapide

```bash
# 1. Cloner le projet
git clone https://github.com/avantgardepreparations-ops/mosaic-agent.git
cd mosaic-agent

# 2. Installer les dÃ©pendances Python
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. Installer Ollama (LLM local)
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama2:7b-chat-q4_0  # ModÃ¨le recommandÃ© pour votre Mac

# 4. Lancer l'interface
python app.py

# 5. Ouvrir dans le navigateur
open http://localhost:5000
```

## ğŸ›ï¸ Interface

### Tableau de bord principal
- **Statistiques systÃ¨me** : RAM/CPU en temps rÃ©el
- **Services actifs** : Ã‰tat de tous les outils IA
- **ModÃ¨les chargÃ©s** : LLM disponibles
- **Actions rapides** : DÃ©marrage/arrÃªt des services

### Cartes d'outils IA
Chaque outil dispose de sa propre carte avec :
- **Ã‰tat de compatibilitÃ©** (âœ… Compatible, âš ï¸ LimitÃ©, âŒ Cloud requis)
- **Configuration recommandÃ©e** pour votre Mac
- **Liens documentation** et installation
- **Boutons d'action** (DÃ©marrer/ArrÃªter/Configurer)

### Configuration et optimisation
- **Recommandations systÃ¨me** spÃ©cifiques Ã  votre MacBook
- **ModÃ¨les optimisÃ©s** (quantifiÃ©s, taille appropriÃ©e)
- **ParamÃ¨tres performance** (RAM, CPU, cache)

## ğŸ“‹ PrÃ©requis SystÃ¨me

- **OS** : macOS 12.0+ (testÃ© sur 12.7.6)
- **RAM** : 8GB (4GB disponibles recommandÃ©s)
- **CPU** : Intel Core i5 ou supÃ©rieur
- **Stockage** : 50GB libres pour modÃ¨les IA
- **Python** : 3.11+

## ğŸ”§ Configuration OptimisÃ©e MacBook Pro 2015

### ModÃ¨les LLM recommandÃ©s
```bash
# Ultra-lÃ©ger (1-2GB) - Tests rapides
ollama pull tinyllama:1.1b-chat

# Optimal (3-4GB) - Usage quotidien
ollama pull llama2:7b-chat-q4_0
ollama pull mistral:7b-instruct-q4_K_M
ollama pull codellama:7b-code-q4_0
```

### Variables d'optimisation
```bash
export OLLAMA_NUM_PARALLEL=1        # Un modÃ¨le Ã  la fois
export OLLAMA_MAX_LOADED_MODELS=1   # Limite mÃ©moire
export OLLAMA_FLASH_ATTENTION=1     # Optimisation Intel
```

## ğŸ¯ Cas d'Usage

### DÃ©veloppement IA Personnel
- **Prototypage rapide** avec JupyterLab + Ollama
- **Agents conversationnels** avec LangChain
- **MÃ©moire persistante** avec ChromaDB
- **Transcription audio** avec Whisper

### Assistance au Codage
- **GÃ©nÃ©ration de code** avec CodeLlama
- **RÃ©vision et debugging** avec Mistral
- **Documentation automatique**
- **Tests unitaires** gÃ©nÃ©rÃ©s par IA

### ExpÃ©rimentation IA
- **Test de nouveaux modÃ¨les** facilement
- **Comparaison de performances**
- **Fine-tuning lÃ©ger** (LoRA, adapters)
- **Ã‰valuation qualitative**

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Interface Web             â”‚
â”‚        (HTML + Tailwind)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Backend Flask              â”‚
â”‚       (Gestion services)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Services IA Locaux              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Ollama  â”‚ Whisper â”‚ Jupyter â”‚    â”‚
â”‚  â”‚  :11434 â”‚   CLI   â”‚  :8888  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       SystÃ¨me macOS 12.7.6         â”‚
â”‚     8GB RAM | Intel CPU            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Documentation

- **[Guide d'Installation Complet](INSTALL.md)** - Instructions dÃ©taillÃ©es
- **[API Documentation](docs/API.md)** - RÃ©fÃ©rence des endpoints
- **[Optimisations MacBook](docs/OPTIMIZATION.md)** - Conseils performance
- **[Troubleshooting](docs/TROUBLESHOOTING.md)** - RÃ©solution de problÃ¨mes

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! 

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/awesome-feature`)
3. Commit les changements (`git commit -m 'Add awesome feature'`)
4. Push vers la branche (`git push origin feature/awesome-feature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“ Inspirations et Remerciements

- **Ollama** pour la simplicitÃ© d'usage des LLM locaux
- **Whisper.cpp** pour les performances CPU exceptionnelles
- **LangChain** pour le framework d'agents flexible
- **Tailwind CSS** pour l'interface moderne et responsive

## ğŸ”® Roadmap

- [ ] **v1.1** : IntÃ©gration Stable Diffusion cloud
- [ ] **v1.2** : Agents LangChain prÃ©dÃ©finis
- [ ] **v1.3** : Interface de fine-tuning LoRA
- [ ] **v1.4** : Support GPU externe (eGPU)
- [ ] **v2.0** : Mode distribuÃ© multi-machines

---

**Note** : Ce projet est spÃ©cialement optimisÃ© pour MacBook Pro 2015. Pour d'autres configurations, consultez la documentation d'optimisation.